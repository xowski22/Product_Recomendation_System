{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-27T11:18:50.882805Z",
     "start_time": "2025-01-27T11:18:49.507956Z"
    }
   },
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from src.models.model import MatrixFactorization\n",
    "from src.data.preprocessing import load_ml1m_data, preprocess_ratings, split_data\n",
    "from src.data.dataset import RecommenderDataset\n",
    "from src.training.trainer import train_model\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T11:18:50.886936Z",
     "start_time": "2025-01-27T11:18:50.885244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparameter_grind = {\n",
    "    'embedding_dim' : [50, 100, 150],\n",
    "    'reg_lambda' : [0.001, 0.01, 0.1],\n",
    "    'dropout' : [0.1, 0.2, 0.3]\n",
    "}"
   ],
   "id": "d914ae10f4864594",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T11:18:50.933879Z",
     "start_time": "2025-01-27T11:18:50.931953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_data(config):\n",
    "\n",
    "    ratings_df, _ = load_ml1m_data('../data/raw/ml-1m')\n",
    "    processed_df, user_mapping, item_mapping = preprocess_ratings(ratings_df)\n",
    "    train_data, val_data = split_data(processed_df)\n",
    "\n",
    "    train_dataset = RecommenderDataset(train_data)\n",
    "    val_dataset = RecommenderDataset(val_data)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['training']['batch_size'],\n",
    "        shuffle=True)\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['training']['batch_size'],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, len(user_mapping), len(item_mapping)"
   ],
   "id": "e945fe12b3d6667d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T11:18:50.977273Z",
     "start_time": "2025-01-27T11:18:50.975326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_hyperparameter_experiment(config, hyperparams, train_loader, val_loader):\n",
    "\n",
    "    model = MatrixFactorization(\n",
    "        num_users=config['num_users'],\n",
    "        n_items=config['n_items'],\n",
    "        embedding_dim=hyperparams['embedding_dim'],\n",
    "        reg_lambda=hyperparams['reg_lambda'],\n",
    "    )\n",
    "\n",
    "    trained_model = train_model(model, train_loader, val_loader, config)\n",
    "    return trained_model\n"
   ],
   "id": "cd868b72f22c7d15",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T11:18:51.024284Z",
     "start_time": "2025-01-27T11:18:51.021989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_experiments(config):\n",
    "\n",
    "    train_loader, val_loader, num_users, n_items = prepare_data(config)\n",
    "\n",
    "    config.update({\n",
    "        'num_users': num_users,\n",
    "        'n_items': n_items\n",
    "    })\n",
    "\n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Hyperparameter_optimization\") as parent_run:\n",
    "        for params in product(*hyperparameter_grind.values()):\n",
    "            hyperparams = dict(zip(hyperparameter_grind.keys(), params))\n",
    "            print(f\"Running experiment with parameters: {hyperparams}\")\n",
    "\n",
    "            with mlflow.start_run(nested=True) as child_run:\n",
    "\n",
    "                model = run_hyperparameter_experiment(\n",
    "                    config,\n",
    "                    hyperparams,\n",
    "                    train_loader,\n",
    "                    val_loader\n",
    "                )\n",
    "\n",
    "                mlflow.log_params(hyperparams)\n",
    "\n",
    "                results.append({\n",
    "                    'params': hyperparams,\n",
    "                    'model': model,\n",
    "                })\n",
    "\n",
    "        return results"
   ],
   "id": "fd2cbcb0913b5d58",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T13:23:43.832779Z",
     "start_time": "2025-01-27T11:18:51.069338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    with open('../config/config.yaml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    results = run_experiments(config)"
   ],
   "id": "bc465cce29698156",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with parameters: {'embedding_dim': 50, 'reg_lambda': 0.001, 'dropout': 0.1}\n",
      "Epoch 1/20 \n",
      "Train Loss: 94.89088502786574\n",
      "Val Loss: 0.8647535067392479\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8385709598594919\n",
      "Val Loss: 0.8324703486422964\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8213156574269939\n",
      "Val Loss: 0.8280007847115846\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.817450431011433\n",
      "Val Loss: 0.8273664490246498\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.816259252036332\n",
      "Val Loss: 0.8272934433690112\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.815735714443491\n",
      "Val Loss: 0.8274022708870399\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8155748762531795\n",
      "Val Loss: 0.8280468696843944\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8154613123834967\n",
      "Val Loss: 0.8277850437883147\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8086220863975639\n",
      "Val Loss: 0.8270461435214648\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8081140956392023\n",
      "Val Loss: 0.8268519423077371\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8079196626683536\n",
      "Val Loss: 0.8267703480489423\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8078077523281962\n",
      "Val Loss: 0.8267185125054264\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8077626013521251\n",
      "Val Loss: 0.826726358119334\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8077311512780916\n",
      "Val Loss: 0.8267090866963068\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8077326014424614\n",
      "Val Loss: 0.8266836890971058\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8077068212894615\n",
      "Val Loss: 0.8267129301519556\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8058966244543723\n",
      "Val Loss: 0.8267076112191721\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8058947758570505\n",
      "Val Loss: 0.8267054744851338\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8058807881419243\n",
      "Val Loss: 0.8267131672644188\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8058885348007163\n",
      "Val Loss: 0.8267156958618151\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 50, 'reg_lambda': 0.001, 'dropout': 0.2}\n",
      "Epoch 1/20 \n",
      "Train Loss: 94.90846191408977\n",
      "Val Loss: 0.8650630751311283\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8386890572003914\n",
      "Val Loss: 0.8324882971386229\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8213189733244844\n",
      "Val Loss: 0.8285726964740667\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8174073922675122\n",
      "Val Loss: 0.8276274991641804\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8162975090270632\n",
      "Val Loss: 0.8275528481076408\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8158294880408282\n",
      "Val Loss: 0.8276012866821567\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8156128408269463\n",
      "Val Loss: 0.8278720716368443\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8154296414605009\n",
      "Val Loss: 0.8278333206571071\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8086158616475312\n",
      "Val Loss: 0.8270048446338374\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8081246450177519\n",
      "Val Loss: 0.82681191184928\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.807907367171187\n",
      "Val Loss: 0.8267245577816313\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8078229149527467\n",
      "Val Loss: 0.8266488547155053\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8077834667033847\n",
      "Val Loss: 0.8266622802756264\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8077462388450295\n",
      "Val Loss: 0.8266589614924374\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8077380520090583\n",
      "Val Loss: 0.8266525482490744\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8059168837503902\n",
      "Val Loss: 0.8266483250187897\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8059181167580152\n",
      "Val Loss: 0.8266482663627474\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8059051261347293\n",
      "Val Loss: 0.8266506667891833\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8059076532205467\n",
      "Val Loss: 0.8266613480950195\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8055147879778514\n",
      "Val Loss: 0.82665913335631\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 50, 'reg_lambda': 0.001, 'dropout': 0.3}\n",
      "Epoch 1/20 \n",
      "Train Loss: 94.83515413409995\n",
      "Val Loss: 0.8649569260372386\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8386796329447262\n",
      "Val Loss: 0.8320526905543745\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8212599203766399\n",
      "Val Loss: 0.8282294544133328\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8174319492643627\n",
      "Val Loss: 0.827697902698587\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8162616519444391\n",
      "Val Loss: 0.8275372764132607\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8158066861964908\n",
      "Val Loss: 0.8278752949162698\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8155949260796069\n",
      "Val Loss: 0.827608415462501\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8155184685659534\n",
      "Val Loss: 0.828190020358837\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8154265475799434\n",
      "Val Loss: 0.828006744623108\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8085336522761225\n",
      "Val Loss: 0.8271575656815439\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8080384281623996\n",
      "Val Loss: 0.8268558653697171\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8078776099181677\n",
      "Val Loss: 0.8267633085563941\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8077745436787805\n",
      "Val Loss: 0.8267998032686578\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.807741441560213\n",
      "Val Loss: 0.8267518619095676\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8077052690802046\n",
      "Val Loss: 0.8267833596847413\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8076893411344942\n",
      "Val Loss: 0.8267870907190894\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8058847195361506\n",
      "Val Loss: 0.826774160200712\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8058779230906679\n",
      "Val Loss: 0.8267794252872009\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8058719839762184\n",
      "Val Loss: 0.8267595429433438\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8058597878971968\n",
      "Val Loss: 0.8267563345460119\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 50, 'reg_lambda': 0.01, 'dropout': 0.1}\n",
      "Epoch 1/20 \n",
      "Train Loss: 95.14701509487627\n",
      "Val Loss: 0.8653551176552656\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8478032688608096\n",
      "Val Loss: 0.8326128211661324\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8303260247244755\n",
      "Val Loss: 0.8281646480954235\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.826542957293113\n",
      "Val Loss: 0.827691677483472\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8251815174190005\n",
      "Val Loss: 0.8275083833572503\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8247897082363654\n",
      "Val Loss: 0.8283078621641535\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8245908685834811\n",
      "Val Loss: 0.8280937620179438\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8244995592184509\n",
      "Val Loss: 0.8278020701906807\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8244451600070535\n",
      "Val Loss: 0.8278930008992963\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8175581254087085\n",
      "Val Loss: 0.8271298178698646\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8170563959197256\n",
      "Val Loss: 0.8269146121966862\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8168733910299402\n",
      "Val Loss: 0.8268481723520897\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.81678769281318\n",
      "Val Loss: 0.8268042597264261\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8167460386604154\n",
      "Val Loss: 0.82681909273602\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.816722440400677\n",
      "Val Loss: 0.8268367575811638\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.816697858952717\n",
      "Val Loss: 0.8267861540528803\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8166855710807308\n",
      "Val Loss: 0.8267924486303742\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8148822905320716\n",
      "Val Loss: 0.8267748303382502\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8148807954198979\n",
      "Val Loss: 0.8267859861407231\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8148836358770278\n",
      "Val Loss: 0.8267714033476526\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 50, 'reg_lambda': 0.01, 'dropout': 0.2}\n",
      "Epoch 1/20 \n",
      "Train Loss: 95.09491730578459\n",
      "Val Loss: 0.8647251636295157\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8476041507327174\n",
      "Val Loss: 0.8322386388700892\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8302872610442078\n",
      "Val Loss: 0.8282511801681149\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8264389999302008\n",
      "Val Loss: 0.8273847769142646\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8252533057384717\n",
      "Val Loss: 0.8275507458379004\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8247942188534938\n",
      "Val Loss: 0.8276588885031368\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8246136181289497\n",
      "Val Loss: 0.8278091396094894\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8244921108117096\n",
      "Val Loss: 0.8279757336954695\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.81761275475086\n",
      "Val Loss: 0.8271797299671082\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.817091902730313\n",
      "Val Loss: 0.8268859202443829\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8168948948535882\n",
      "Val Loss: 0.8267547765500028\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8168015855627518\n",
      "Val Loss: 0.8267712031401127\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8167769659722051\n",
      "Val Loss: 0.8266991362147277\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8167443020881714\n",
      "Val Loss: 0.8266832777087458\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8167245857936616\n",
      "Val Loss: 0.8266624689283313\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8167013513138988\n",
      "Val Loss: 0.8267695614716523\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8167058980904474\n",
      "Val Loss: 0.8266785943633993\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8166878886564364\n",
      "Val Loss: 0.8267402481275801\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8166916001885164\n",
      "Val Loss: 0.8267506315007624\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8148820987322097\n",
      "Val Loss: 0.8267388192702011\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 50, 'reg_lambda': 0.01, 'dropout': 0.3}\n",
      "Epoch 1/20 \n",
      "Train Loss: 94.9031219134891\n",
      "Val Loss: 0.8648297904120068\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8477278636220378\n",
      "Val Loss: 0.8323607954958732\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8303340763618763\n",
      "Val Loss: 0.8280992807578522\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8264577375725061\n",
      "Val Loss: 0.827305399729934\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.825292001426158\n",
      "Val Loss: 0.8271326645017052\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.824822604289143\n",
      "Val Loss: 0.8276778691932702\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8245524000136611\n",
      "Val Loss: 0.827656950351144\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8245281569721088\n",
      "Val Loss: 0.8280880709851467\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8244324849456213\n",
      "Val Loss: 0.8280742350186359\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8175818549984123\n",
      "Val Loss: 0.8272741053846885\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8170774154836422\n",
      "Val Loss: 0.8270036340455786\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8168841895580978\n",
      "Val Loss: 0.8268240718069705\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8167918077838008\n",
      "Val Loss: 0.8267783060221815\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.816747342795074\n",
      "Val Loss: 0.826746699739288\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8167176603684566\n",
      "Val Loss: 0.8267821530672654\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8166948726446469\n",
      "Val Loss: 0.8268083937737855\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8149018807024285\n",
      "Val Loss: 0.8267894755198035\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8148889655443532\n",
      "Val Loss: 0.8267906777565478\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8149009721785233\n",
      "Val Loss: 0.8267911263787434\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8148804850590894\n",
      "Val Loss: 0.8267856020377907\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 50, 'reg_lambda': 0.1, 'dropout': 0.1}\n",
      "Epoch 1/20 \n",
      "Train Loss: 94.81420013064205\n",
      "Val Loss: 0.8649572915637714\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.9377065619892819\n",
      "Val Loss: 0.8324634724189971\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.9202712658981338\n",
      "Val Loss: 0.8281727601474321\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.916512826714603\n",
      "Val Loss: 0.82777982474956\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.9152586173340959\n",
      "Val Loss: 0.8273059556204695\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.9147396218959765\n",
      "Val Loss: 0.8279350018289634\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.9146002912596685\n",
      "Val Loss: 0.8274608671245709\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.9144747917779701\n",
      "Val Loss: 0.8276619854182368\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.9143413153541743\n",
      "Val Loss: 0.827812882403647\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.9075931916401442\n",
      "Val Loss: 0.8269342339799638\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.9070723958466612\n",
      "Val Loss: 0.8267415139349851\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.9068802496981336\n",
      "Val Loss: 0.826671028968545\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.9067792796324913\n",
      "Val Loss: 0.826705760905854\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.9067395274962157\n",
      "Val Loss: 0.826664012156651\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.9067131564835115\n",
      "Val Loss: 0.8266679396803991\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.9049132166505289\n",
      "Val Loss: 0.8266651767829787\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.9048951270984934\n",
      "Val Loss: 0.8266685466667588\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.9048853890162454\n",
      "Val Loss: 0.8266761398809275\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.9048800973580244\n",
      "Val Loss: 0.8266766357759368\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.9045081989823137\n",
      "Val Loss: 0.8266749660164519\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 50, 'reg_lambda': 0.1, 'dropout': 0.2}\n",
      "Epoch 1/20 \n",
      "Train Loss: 94.94896465020781\n",
      "Val Loss: 0.8648097850072483\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.9377668266566974\n",
      "Val Loss: 0.832360403665883\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.9202578196303993\n",
      "Val Loss: 0.8284587044595375\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.9164655766853816\n",
      "Val Loss: 0.8276330814795164\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.9152876883256552\n",
      "Val Loss: 0.8275233966108323\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.9148617767266518\n",
      "Val Loss: 0.8275547396017433\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.9146246106316831\n",
      "Val Loss: 0.8278001167132774\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.9144596269914821\n",
      "Val Loss: 0.8279527650379783\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.9144147480524779\n",
      "Val Loss: 0.8279146528775999\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.9075502125962128\n",
      "Val Loss: 0.8271250967377283\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.9070504498412149\n",
      "Val Loss: 0.8268933381863839\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.9068694917557669\n",
      "Val Loss: 0.8268338645250082\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.9067967457646591\n",
      "Val Loss: 0.8268114496940081\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.9067419405046638\n",
      "Val Loss: 0.8268027467532792\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.9067191832863426\n",
      "Val Loss: 0.826805877698894\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.9067176814261584\n",
      "Val Loss: 0.826791161629571\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.9066921413984049\n",
      "Val Loss: 0.8268183295401105\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.9066754222645584\n",
      "Val Loss: 0.8268468925444575\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.9048760708194727\n",
      "Val Loss: 0.8268323553701051\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.9048607279079147\n",
      "Val Loss: 0.8268231969619896\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 50, 'reg_lambda': 0.1, 'dropout': 0.3}\n",
      "Epoch 1/20 \n",
      "Train Loss: 95.234004438772\n",
      "Val Loss: 0.8650488012296911\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.9376501192176455\n",
      "Val Loss: 0.8324290408740346\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.9203703879337545\n",
      "Val Loss: 0.8281791014352519\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.9164528426604968\n",
      "Val Loss: 0.8273003582657337\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.9151948222558727\n",
      "Val Loss: 0.8275537636471878\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.914789298317637\n",
      "Val Loss: 0.8276212690058459\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.9145774669688406\n",
      "Val Loss: 0.8278605709101478\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.9144587450710896\n",
      "Val Loss: 0.8278818212625924\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.9076101083207453\n",
      "Val Loss: 0.8270628825402077\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.9070773921465384\n",
      "Val Loss: 0.8269031369726169\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.9069026423188998\n",
      "Val Loss: 0.8267011241516622\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.9068086986602578\n",
      "Val Loss: 0.8266685098238046\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.9067798098244592\n",
      "Val Loss: 0.8266333573457909\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.9067447540269588\n",
      "Val Loss: 0.8266473530731518\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.9067097972137855\n",
      "Val Loss: 0.8266497724335009\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.9049045494234315\n",
      "Val Loss: 0.8266240146752358\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.9048868048136725\n",
      "Val Loss: 0.8266192657666869\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.9049080836194178\n",
      "Val Loss: 0.8266162452545978\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.9048903450354342\n",
      "Val Loss: 0.8266128689069742\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.9048828555471105\n",
      "Val Loss: 0.826612293419934\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 100, 'reg_lambda': 0.001, 'dropout': 0.1}\n",
      "Epoch 1/20 \n",
      "Train Loss: 187.53939570690463\n",
      "Val Loss: 0.8653041217059031\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8388787688188226\n",
      "Val Loss: 0.8328570320687458\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8213405743161459\n",
      "Val Loss: 0.8280696349834603\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8174852181780503\n",
      "Val Loss: 0.8277412108357183\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8161781421091369\n",
      "Val Loss: 0.8273800972155555\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8158291087196912\n",
      "Val Loss: 0.8277976910368571\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.81561208565283\n",
      "Val Loss: 0.8279709935054822\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.815463051706431\n",
      "Val Loss: 0.8280056692369078\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8154282833846638\n",
      "Val Loss: 0.8280133298495147\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.808587419336475\n",
      "Val Loss: 0.8271797802954702\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8080650760032344\n",
      "Val Loss: 0.8269001827673582\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8078675127778827\n",
      "Val Loss: 0.8268372867487594\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.807777942092211\n",
      "Val Loss: 0.8267912803240411\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8077394935542809\n",
      "Val Loss: 0.8267565522097428\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8077125798547057\n",
      "Val Loss: 0.8267843104703488\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8077074278738654\n",
      "Val Loss: 0.8267453679920997\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8076896184512656\n",
      "Val Loss: 0.8267639564184599\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8058842490703919\n",
      "Val Loss: 0.8267562930410822\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.805872058971857\n",
      "Val Loss: 0.8267570556220685\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8058749063438505\n",
      "Val Loss: 0.8267539813065864\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 100, 'reg_lambda': 0.001, 'dropout': 0.2}\n",
      "Epoch 1/20 \n",
      "Train Loss: 188.0443377218146\n",
      "Val Loss: 0.8649535069596058\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8388358820803326\n",
      "Val Loss: 0.8324581288606863\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8213144480934202\n",
      "Val Loss: 0.82770864959146\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8174274120508723\n",
      "Val Loss: 0.8272435435559302\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8162633421696979\n",
      "Val Loss: 0.8275399547801976\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8157694385326891\n",
      "Val Loss: 0.827408413473643\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8156574218619073\n",
      "Val Loss: 0.8277312225673493\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8154539101378189\n",
      "Val Loss: 0.8276681121741436\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8086108958722115\n",
      "Val Loss: 0.8269184190095882\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8080973131918081\n",
      "Val Loss: 0.8267058949114341\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8079052015580073\n",
      "Val Loss: 0.8266836501710398\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8078059502280275\n",
      "Val Loss: 0.826647895831026\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8077650909055607\n",
      "Val Loss: 0.8266853695057251\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8077439318835559\n",
      "Val Loss: 0.8266930317485935\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8059308846492839\n",
      "Val Loss: 0.8266724713780678\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.805917429652756\n",
      "Val Loss: 0.8266709978791742\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8059095745943626\n",
      "Val Loss: 0.8266759205440337\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8059143739457723\n",
      "Val Loss: 0.8266764860635984\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.805513742143494\n",
      "Val Loss: 0.8266739169766105\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8055090153492861\n",
      "Val Loss: 0.8266728649336561\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 100, 'reg_lambda': 0.001, 'dropout': 0.3}\n",
      "Epoch 1/20 \n",
      "Train Loss: 188.3033237477274\n",
      "Val Loss: 0.8660089290502433\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8389859469944903\n",
      "Val Loss: 0.8325776564182567\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.82132086009538\n",
      "Val Loss: 0.8283865444138122\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8174252322909451\n",
      "Val Loss: 0.8274426422655696\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8162161574967811\n",
      "Val Loss: 0.8277508266131922\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8157906386863324\n",
      "Val Loss: 0.8274582188793351\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8155963358441076\n",
      "Val Loss: 0.8278688032153854\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8154325001808793\n",
      "Val Loss: 0.8277070131712972\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8086029019540171\n",
      "Val Loss: 0.8269283436310269\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8081104859446351\n",
      "Val Loss: 0.826687292503914\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8079232057742879\n",
      "Val Loss: 0.8265976624388155\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8078073591058239\n",
      "Val Loss: 0.826572260763961\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8077646883275045\n",
      "Val Loss: 0.826625682508915\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8077288611353964\n",
      "Val Loss: 0.8266102008507257\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.807708669924921\n",
      "Val Loss: 0.8267296942300089\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8059194828070403\n",
      "Val Loss: 0.8266393472884453\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8059260991442865\n",
      "Val Loss: 0.8266403126320012\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8058921870999953\n",
      "Val Loss: 0.8266424409334887\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8059056630866257\n",
      "Val Loss: 0.8266323749416925\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8055180391673802\n",
      "Val Loss: 0.8266336059225193\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 100, 'reg_lambda': 0.01, 'dropout': 0.1}\n",
      "Epoch 1/20 \n",
      "Train Loss: 188.1166064147376\n",
      "Val Loss: 0.8655087083091891\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8478741605911294\n",
      "Val Loss: 0.8327162647887979\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8303098814168816\n",
      "Val Loss: 0.8281358177615753\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8264367123379723\n",
      "Val Loss: 0.8276559120843751\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8252756720346078\n",
      "Val Loss: 0.8274499273174326\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8248427836411402\n",
      "Val Loss: 0.827658108833007\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8246091685418672\n",
      "Val Loss: 0.8276576393224914\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8245029477184318\n",
      "Val Loss: 0.8281366180816828\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8243671018085909\n",
      "Val Loss: 0.8281300004979242\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8176143357160329\n",
      "Val Loss: 0.8271379123751124\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8170624930129416\n",
      "Val Loss: 0.826885266647801\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8168540224307805\n",
      "Val Loss: 0.8268343692863513\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8167785563574194\n",
      "Val Loss: 0.8267898472813712\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8167367263916901\n",
      "Val Loss: 0.8267860245901045\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8167159149911436\n",
      "Val Loss: 0.826783201849697\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.816699121395588\n",
      "Val Loss: 0.8267676619120462\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8166864603617225\n",
      "Val Loss: 0.8267779360291139\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8148750976368035\n",
      "Val Loss: 0.8267706977543127\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8148807492969723\n",
      "Val Loss: 0.8267730619098159\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8148790943062917\n",
      "Val Loss: 0.8267675082241581\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 100, 'reg_lambda': 0.01, 'dropout': 0.2}\n",
      "Epoch 1/20 \n",
      "Train Loss: 188.17788856901245\n",
      "Val Loss: 0.865347713184372\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8479219999902965\n",
      "Val Loss: 0.8324434422981412\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8303405518084824\n",
      "Val Loss: 0.828200227897364\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8265567310860583\n",
      "Val Loss: 0.8277156028279263\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8252869955322356\n",
      "Val Loss: 0.8278059304971308\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.824793161179727\n",
      "Val Loss: 0.82749722806483\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8245872993602912\n",
      "Val Loss: 0.8278969886712134\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8244797001812331\n",
      "Val Loss: 0.8280191019043965\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8244760490070198\n",
      "Val Loss: 0.8277421003816529\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8243827389510433\n",
      "Val Loss: 0.8282368683511832\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8175263906525372\n",
      "Val Loss: 0.827383635097296\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8170511313989469\n",
      "Val Loss: 0.8270940457209134\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8168555069740111\n",
      "Val Loss: 0.8269443980210192\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8167821176622445\n",
      "Val Loss: 0.826878846959662\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.816733763588435\n",
      "Val Loss: 0.826844112977376\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8167056126813074\n",
      "Val Loss: 0.8268204340645692\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8166848467434252\n",
      "Val Loss: 0.8267998842335403\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.816684245405355\n",
      "Val Loss: 0.8268380853242013\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8166690755250844\n",
      "Val Loss: 0.826816968696093\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8148724696383155\n",
      "Val Loss: 0.8268248855076153\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 100, 'reg_lambda': 0.01, 'dropout': 0.3}\n",
      "Epoch 1/20 \n",
      "Train Loss: 188.34970424447567\n",
      "Val Loss: 0.8651128079282192\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8478859654833848\n",
      "Val Loss: 0.8323071082423531\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8303457119675014\n",
      "Val Loss: 0.8280513241686885\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.826490329843249\n",
      "Val Loss: 0.8273213756052028\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8252787676194492\n",
      "Val Loss: 0.8271723813493512\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8248663298999616\n",
      "Val Loss: 0.8274587764430336\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8246059546654275\n",
      "Val Loss: 0.8275836505238932\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8244320213470537\n",
      "Val Loss: 0.8281551592828978\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8244147860488061\n",
      "Val Loss: 0.8279015832245159\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8175586309135889\n",
      "Val Loss: 0.827109213639587\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8170471490597445\n",
      "Val Loss: 0.8268258793902794\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8168568592147618\n",
      "Val Loss: 0.8267104934784212\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8167971959950627\n",
      "Val Loss: 0.8267086112701352\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8167402360293042\n",
      "Val Loss: 0.8266858138901945\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8167306515471244\n",
      "Val Loss: 0.8267184858206214\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8167108227841846\n",
      "Val Loss: 0.8267354165142496\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8148990570593098\n",
      "Val Loss: 0.8267099595582797\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.814877410171166\n",
      "Val Loss: 0.8267121185773241\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8148757500342633\n",
      "Val Loss: 0.8267148025453053\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8148691568037686\n",
      "Val Loss: 0.8267051803087547\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 100, 'reg_lambda': 0.1, 'dropout': 0.1}\n",
      "Epoch 1/20 \n",
      "Train Loss: 188.0555827725051\n",
      "Val Loss: 0.8652321983293242\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.9378282998544087\n",
      "Val Loss: 0.8323264194703682\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.9203066590723206\n",
      "Val Loss: 0.8279379758309342\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.9163707694029661\n",
      "Val Loss: 0.82766577412189\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.9152884379817058\n",
      "Val Loss: 0.8273485929860721\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.9148416691166605\n",
      "Val Loss: 0.8272120288632195\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.9145869241898835\n",
      "Val Loss: 0.8278407365541312\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.9145086194566371\n",
      "Val Loss: 0.82795930808733\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.9144641543296607\n",
      "Val Loss: 0.828063553174146\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.9143702330960566\n",
      "Val Loss: 0.8281354563583644\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.9075082107004258\n",
      "Val Loss: 0.8273139681502634\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.9070148857094846\n",
      "Val Loss: 0.8270692866359929\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.906841876897146\n",
      "Val Loss: 0.8269084870710407\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.9067657516163405\n",
      "Val Loss: 0.8268264313958351\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.9067178840118724\n",
      "Val Loss: 0.8268676735770604\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.9067057601634974\n",
      "Val Loss: 0.8268829291723359\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.9066849111805132\n",
      "Val Loss: 0.8268643810591939\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.904878061501625\n",
      "Val Loss: 0.8268537819862213\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.904864853366436\n",
      "Val Loss: 0.8268642908561634\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.9048631254562443\n",
      "Val Loss: 0.8268551677179428\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 100, 'reg_lambda': 0.1, 'dropout': 0.2}\n",
      "Epoch 1/20 \n",
      "Train Loss: 188.45768736515828\n",
      "Val Loss: 0.865563534710244\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.9379001733999887\n",
      "Val Loss: 0.8326799230446285\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.9203722153145304\n",
      "Val Loss: 0.8280428546079823\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.9164841438873876\n",
      "Val Loss: 0.827469114011591\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.9152403983852058\n",
      "Val Loss: 0.8273645865749413\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.9147659427550643\n",
      "Val Loss: 0.827302023582518\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.9146124929711693\n",
      "Val Loss: 0.827587563523061\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.9145140455697409\n",
      "Val Loss: 0.8275953021355722\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.9143296160583905\n",
      "Val Loss: 0.8278588993344944\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.9076092782010462\n",
      "Val Loss: 0.8270441355923773\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.90705757691299\n",
      "Val Loss: 0.8268352028409106\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.9068666869622655\n",
      "Val Loss: 0.8267853789064874\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.9067905266089678\n",
      "Val Loss: 0.8267858530503774\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.9067555210842644\n",
      "Val Loss: 0.8267601043491202\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.9066988353484975\n",
      "Val Loss: 0.8267396059571286\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.9066900892237859\n",
      "Val Loss: 0.8267787606220023\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.906680827695046\n",
      "Val Loss: 0.8267549710945296\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.906673684676895\n",
      "Val Loss: 0.8267796237071736\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.9066694975542867\n",
      "Val Loss: 0.826786057643416\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.9048633641108011\n",
      "Val Loss: 0.8267869015896999\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 100, 'reg_lambda': 0.1, 'dropout': 0.3}\n",
      "Epoch 1/20 \n",
      "Train Loss: 188.57672190324388\n",
      "Val Loss: 0.8645459724565157\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.9377708130623449\n",
      "Val Loss: 0.8323524716528882\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.92031785489883\n",
      "Val Loss: 0.8280488218080135\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.916450336045154\n",
      "Val Loss: 0.8275897139188806\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.9152524558261024\n",
      "Val Loss: 0.8272315348264352\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.9148224397777491\n",
      "Val Loss: 0.8272327021078962\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.9145717806223249\n",
      "Val Loss: 0.827743533295618\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.9145012940682001\n",
      "Val Loss: 0.82787098906224\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.9144428850917409\n",
      "Val Loss: 0.8278770150565521\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.9075771822415857\n",
      "Val Loss: 0.8271232152587698\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.9070410021999155\n",
      "Val Loss: 0.8268775216953844\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.9068714981745369\n",
      "Val Loss: 0.8268133794325174\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.9068002374369765\n",
      "Val Loss: 0.8267746905028172\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.9067455328203036\n",
      "Val Loss: 0.8267683459497078\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.9067222032772583\n",
      "Val Loss: 0.8267604724306825\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.9067172364436139\n",
      "Val Loss: 0.8267474952305804\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.9066824328157603\n",
      "Val Loss: 0.8267779475124464\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.9048859868933085\n",
      "Val Loss: 0.8267368740585089\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.9048907181281887\n",
      "Val Loss: 0.826741660839651\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.9048781904360585\n",
      "Val Loss: 0.8267436947003818\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 150, 'reg_lambda': 0.001, 'dropout': 0.1}\n",
      "Epoch 1/20 \n",
      "Train Loss: 281.5883179624529\n",
      "Val Loss: 0.8653771280241332\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8390787802562135\n",
      "Val Loss: 0.8326485944162251\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8213896982209126\n",
      "Val Loss: 0.8279514668446203\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8175600848249995\n",
      "Val Loss: 0.827439325331917\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.816277398263551\n",
      "Val Loss: 0.8276142623616348\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8157718781351156\n",
      "Val Loss: 0.8276789076030445\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8156471010623794\n",
      "Val Loss: 0.8277196767510547\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.815511755065461\n",
      "Val Loss: 0.8278449412318506\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8085981428022528\n",
      "Val Loss: 0.8270005969734658\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8081168081153444\n",
      "Val Loss: 0.826755149164836\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8079039630394673\n",
      "Val Loss: 0.8266988800968487\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8078145407647369\n",
      "Val Loss: 0.826663293697593\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8077854228040691\n",
      "Val Loss: 0.8266396284370336\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8077531367847846\n",
      "Val Loss: 0.8266431202519725\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8077272961332848\n",
      "Val Loss: 0.8266330450935312\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.807721864792916\n",
      "Val Loss: 0.8266794888477865\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8059107908356488\n",
      "Val Loss: 0.8266791606361258\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8058917794662943\n",
      "Val Loss: 0.8266832805974546\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8058944659157581\n",
      "Val Loss: 0.8266794004370902\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8058847828425475\n",
      "Val Loss: 0.8266757729672425\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 150, 'reg_lambda': 0.001, 'dropout': 0.2}\n",
      "Epoch 1/20 \n",
      "Train Loss: 282.7228093081776\n",
      "Val Loss: 0.8655364673563248\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8392845756038135\n",
      "Val Loss: 0.8327896930825535\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8213849702992554\n",
      "Val Loss: 0.8279423152244938\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8175438918548137\n",
      "Val Loss: 0.8276038325164689\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8162433800221176\n",
      "Val Loss: 0.8275449255759031\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8157299401344781\n",
      "Val Loss: 0.827891918820444\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8155634273250303\n",
      "Val Loss: 0.8277084525491057\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8154922983989252\n",
      "Val Loss: 0.8279361571027389\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8085991704687066\n",
      "Val Loss: 0.8270838374292248\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8081050554361475\n",
      "Val Loss: 0.8268009502528878\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8079016037767414\n",
      "Val Loss: 0.8267172276258697\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8078184471858422\n",
      "Val Loss: 0.8267629712924923\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8077737253317497\n",
      "Val Loss: 0.8266693419864448\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8077349668191565\n",
      "Val Loss: 0.826666950140332\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8077299300026133\n",
      "Val Loss: 0.8266778885221833\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8059068931600223\n",
      "Val Loss: 0.8266642259020341\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.805891997628924\n",
      "Val Loss: 0.8266578240800346\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8058959715968751\n",
      "Val Loss: 0.8266527250847676\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8058816566354207\n",
      "Val Loss: 0.8266490616967338\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8055016095830109\n",
      "Val Loss: 0.8266495804869053\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 150, 'reg_lambda': 0.001, 'dropout': 0.3}\n",
      "Epoch 1/20 \n",
      "Train Loss: 282.4656625281503\n",
      "Val Loss: 0.8658988804282931\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8391457050073379\n",
      "Val Loss: 0.8322635258161252\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8212690347291504\n",
      "Val Loss: 0.8280688893390785\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8174538678248806\n",
      "Val Loss: 0.8275064526272369\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8163017036437531\n",
      "Val Loss: 0.8274423704886009\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8157675617372171\n",
      "Val Loss: 0.827467576865767\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8156646069937454\n",
      "Val Loss: 0.8276279538450375\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8154984433288852\n",
      "Val Loss: 0.8278918164381215\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8086095777147533\n",
      "Val Loss: 0.8270307485197724\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8081064561762867\n",
      "Val Loss: 0.8267264305181939\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8079122175915208\n",
      "Val Loss: 0.826638756066046\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.807822413299786\n",
      "Val Loss: 0.8266966574928429\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8077699692785325\n",
      "Val Loss: 0.8265857054439021\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.807748655738768\n",
      "Val Loss: 0.8266194332498278\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8077122153429607\n",
      "Val Loss: 0.8266431227450332\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8059176857625161\n",
      "Val Loss: 0.8266497805895747\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8059104879784563\n",
      "Val Loss: 0.8266429721794293\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8059145757663463\n",
      "Val Loss: 0.8266417776649759\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8058957018004049\n",
      "Val Loss: 0.8266394686761835\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8055173561833892\n",
      "Val Loss: 0.8266407363426587\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 150, 'reg_lambda': 0.01, 'dropout': 0.1}\n",
      "Epoch 1/20 \n",
      "Train Loss: 282.1423770206853\n",
      "Val Loss: 0.8652683312856304\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8482739319565258\n",
      "Val Loss: 0.8321921871981023\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8303745666151284\n",
      "Val Loss: 0.8281141354184615\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8264632098871947\n",
      "Val Loss: 0.8273906065574153\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8252354457117524\n",
      "Val Loss: 0.8277328302624969\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8249008553100378\n",
      "Val Loss: 0.8277641646349498\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8245468443416171\n",
      "Val Loss: 0.8277552923043416\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8244734537283973\n",
      "Val Loss: 0.8275817473891525\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8175763279273492\n",
      "Val Loss: 0.826807905353191\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8170650311801793\n",
      "Val Loss: 0.8266489436076531\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8169037250316706\n",
      "Val Loss: 0.826573975736982\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8168079633241003\n",
      "Val Loss: 0.8265771296683291\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8167723331543519\n",
      "Val Loss: 0.8265955685730249\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8167450228143023\n",
      "Val Loss: 0.8266188651561661\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8149272395230994\n",
      "Val Loss: 0.8266133983653475\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8149213951906662\n",
      "Val Loss: 0.8266128790937245\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8149080601328136\n",
      "Val Loss: 0.8266204136041823\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8149039568132966\n",
      "Val Loss: 0.8266221551809719\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8145312356618007\n",
      "Val Loss: 0.8266206814437361\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8145243613770282\n",
      "Val Loss: 0.8266191627313064\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 150, 'reg_lambda': 0.01, 'dropout': 0.2}\n",
      "Epoch 1/20 \n",
      "Train Loss: 282.84947077749655\n",
      "Val Loss: 0.8653085825491699\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.848128734855931\n",
      "Val Loss: 0.8322925138563128\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8304516520775157\n",
      "Val Loss: 0.827714442000775\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8264261660056811\n",
      "Val Loss: 0.8272271769851809\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.8252351557427594\n",
      "Val Loss: 0.8273738596209409\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8248405353570856\n",
      "Val Loss: 0.8277593504587428\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8246068669268392\n",
      "Val Loss: 0.8277598125329784\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8244386219834362\n",
      "Val Loss: 0.8279010895127222\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8176502471283646\n",
      "Val Loss: 0.8270613892350682\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8171142756576625\n",
      "Val Loss: 0.8267477719507688\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8169018224359637\n",
      "Val Loss: 0.826684841901655\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8168000535879919\n",
      "Val Loss: 0.8266596017799848\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.816784161527586\n",
      "Val Loss: 0.8266360064538258\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8167428159050147\n",
      "Val Loss: 0.8266188673060137\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8167207351991732\n",
      "Val Loss: 0.8266606880870295\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8167297709758574\n",
      "Val Loss: 0.8266748281163584\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.8149013643783254\n",
      "Val Loss: 0.8266652612943949\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.8149031828181663\n",
      "Val Loss: 0.8266575972305912\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.8148957281472883\n",
      "Val Loss: 0.8266624869565435\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8148907056443455\n",
      "Val Loss: 0.8266686258250067\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 150, 'reg_lambda': 0.01, 'dropout': 0.3}\n",
      "Epoch 1/20 \n",
      "Train Loss: 282.6633275717623\n",
      "Val Loss: 0.8651739466346691\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.8481404782271162\n",
      "Val Loss: 0.8330494928497271\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.8303973411956921\n",
      "Val Loss: 0.8282051791299327\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.8264559863410377\n",
      "Val Loss: 0.8276439182751085\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.825225922595708\n",
      "Val Loss: 0.8278252252604591\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.8248479608525316\n",
      "Val Loss: 0.8275729977142635\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.8246028207997499\n",
      "Val Loss: 0.8278289877369247\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.8245287842486636\n",
      "Val Loss: 0.8278119957893229\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.8175854950983563\n",
      "Val Loss: 0.8270066854754321\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.8170907907316058\n",
      "Val Loss: 0.8267982084296944\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.8168825279743416\n",
      "Val Loss: 0.8267493595631933\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.8168153512442597\n",
      "Val Loss: 0.8266863471954127\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.8167803951294853\n",
      "Val Loss: 0.8266978740062915\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.8167404858773111\n",
      "Val Loss: 0.8266921473079512\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.8167184575203942\n",
      "Val Loss: 0.826693498317965\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.8167166193346972\n",
      "Val Loss: 0.8267085599073675\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.814897752702975\n",
      "Val Loss: 0.8266856029667842\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.814884615933181\n",
      "Val Loss: 0.826696725363199\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.814879129619529\n",
      "Val Loss: 0.8266978116416428\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.8148757790428424\n",
      "Val Loss: 0.8266874503103572\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 150, 'reg_lambda': 0.1, 'dropout': 0.1}\n",
      "Epoch 1/20 \n",
      "Train Loss: 281.8886103466383\n",
      "Val Loss: 0.8652245004638143\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.9380712198189027\n",
      "Val Loss: 0.8324617419727933\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.9203389644084106\n",
      "Val Loss: 0.8277868988255774\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.916529387319068\n",
      "Val Loss: 0.8272558224702674\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.9152115448793297\n",
      "Val Loss: 0.8273244935945296\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.9147844215059322\n",
      "Val Loss: 0.8278708131465482\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.9146217197682737\n",
      "Val Loss: 0.8277063128643897\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.9145157509619337\n",
      "Val Loss: 0.8280471310744054\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.907569893234245\n",
      "Val Loss: 0.8271617445563249\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.9070740411598701\n",
      "Val Loss: 0.8268303047014747\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.9068776497380939\n",
      "Val Loss: 0.8267456540267054\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.9068032871587061\n",
      "Val Loss: 0.8267658949947022\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.9067569325697343\n",
      "Val Loss: 0.8267255329496572\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.9067471182452177\n",
      "Val Loss: 0.8266975790195487\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.9067122869126217\n",
      "Val Loss: 0.8267085551357544\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.9049034932775611\n",
      "Val Loss: 0.8266933650703134\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.9049053763633899\n",
      "Val Loss: 0.8266883727522973\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.9049000231793315\n",
      "Val Loss: 0.8266779196735231\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.9049007613964198\n",
      "Val Loss: 0.8266812256672638\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.9044913647437605\n",
      "Val Loss: 0.8266736389407727\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 150, 'reg_lambda': 0.1, 'dropout': 0.2}\n",
      "Epoch 1/20 \n",
      "Train Loss: 281.60057061259425\n",
      "Val Loss: 0.8654896021842652\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.9381097250034129\n",
      "Val Loss: 0.8325626093629683\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.9203024143925916\n",
      "Val Loss: 0.8282861654871332\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.9164894920873097\n",
      "Val Loss: 0.8277672385643173\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.9152799533799411\n",
      "Val Loss: 0.8280329268070573\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.9147968629040947\n",
      "Val Loss: 0.8276518233840235\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.9146074149157251\n",
      "Val Loss: 0.827438099380113\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.9144823304545466\n",
      "Val Loss: 0.8279199640642583\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.914418372477778\n",
      "Val Loss: 0.8279425020943981\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.9144437631602136\n",
      "Val Loss: 0.8278886102240054\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.9143562618874554\n",
      "Val Loss: 0.8283997335717301\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.9075102899528966\n",
      "Val Loss: 0.8273619692951384\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.9070139242049972\n",
      "Val Loss: 0.8271216432529996\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.9068375108056685\n",
      "Val Loss: 0.8269963096290999\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.9067431772259591\n",
      "Val Loss: 0.8269740984473027\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.9067075057338831\n",
      "Val Loss: 0.8269608258123743\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.90667954798051\n",
      "Val Loss: 0.8269467899529352\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.9066800217618753\n",
      "Val Loss: 0.8269183549670096\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.9048750441422189\n",
      "Val Loss: 0.8269084992360322\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.9048523787883704\n",
      "Val Loss: 0.8269058420338924\n",
      "----------------------------------------\n",
      "Running experiment with parameters: {'embedding_dim': 150, 'reg_lambda': 0.1, 'dropout': 0.3}\n",
      "Epoch 1/20 \n",
      "Train Loss: 281.73226319364403\n",
      "Val Loss: 0.8652880748808955\n",
      "----------------------------------------\n",
      "Epoch 2/20 \n",
      "Train Loss: 0.9380334060182383\n",
      "Val Loss: 0.8324157228491966\n",
      "----------------------------------------\n",
      "Epoch 3/20 \n",
      "Train Loss: 0.9203646567729171\n",
      "Val Loss: 0.8282559330379131\n",
      "----------------------------------------\n",
      "Epoch 4/20 \n",
      "Train Loss: 0.9165761505237896\n",
      "Val Loss: 0.8274437934017227\n",
      "----------------------------------------\n",
      "Epoch 5/20 \n",
      "Train Loss: 0.9153172960688875\n",
      "Val Loss: 0.8274685428147124\n",
      "----------------------------------------\n",
      "Epoch 6/20 \n",
      "Train Loss: 0.9148136974358324\n",
      "Val Loss: 0.8283072427649263\n",
      "----------------------------------------\n",
      "Epoch 7/20 \n",
      "Train Loss: 0.9145580851096378\n",
      "Val Loss: 0.8277187621553433\n",
      "----------------------------------------\n",
      "Epoch 8/20 \n",
      "Train Loss: 0.9145125798737441\n",
      "Val Loss: 0.8279763593630995\n",
      "----------------------------------------\n",
      "Epoch 9/20 \n",
      "Train Loss: 0.9076132090422742\n",
      "Val Loss: 0.8270076062251419\n",
      "----------------------------------------\n",
      "Epoch 10/20 \n",
      "Train Loss: 0.9071047190455526\n",
      "Val Loss: 0.8267423145506372\n",
      "----------------------------------------\n",
      "Epoch 11/20 \n",
      "Train Loss: 0.9069049146130954\n",
      "Val Loss: 0.8266494055388832\n",
      "----------------------------------------\n",
      "Epoch 12/20 \n",
      "Train Loss: 0.9067993730885844\n",
      "Val Loss: 0.8266682085305243\n",
      "----------------------------------------\n",
      "Epoch 13/20 \n",
      "Train Loss: 0.9067643404693438\n",
      "Val Loss: 0.8265992149243504\n",
      "----------------------------------------\n",
      "Epoch 14/20 \n",
      "Train Loss: 0.9067402177621467\n",
      "Val Loss: 0.8265951477749105\n",
      "----------------------------------------\n",
      "Epoch 15/20 \n",
      "Train Loss: 0.9067170483812583\n",
      "Val Loss: 0.8267497061939477\n",
      "----------------------------------------\n",
      "Epoch 16/20 \n",
      "Train Loss: 0.9049291008092551\n",
      "Val Loss: 0.8266368001289499\n",
      "----------------------------------------\n",
      "Epoch 17/20 \n",
      "Train Loss: 0.904897567971386\n",
      "Val Loss: 0.8266315771432466\n",
      "----------------------------------------\n",
      "Epoch 18/20 \n",
      "Train Loss: 0.9049015544842961\n",
      "Val Loss: 0.8266277458907242\n",
      "----------------------------------------\n",
      "Epoch 19/20 \n",
      "Train Loss: 0.9048924258086507\n",
      "Val Loss: 0.8266276182155158\n",
      "----------------------------------------\n",
      "Epoch 20/20 \n",
      "Train Loss: 0.9045111927201078\n",
      "Val Loss: 0.8266278381673328\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
